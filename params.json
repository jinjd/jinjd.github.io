{"name":"Jinjd.GitHub.io","tagline":"MyCould-cloreda","body":"cloreda笔记\r\n初步感觉，安装很恶心，主要是自动安装不能用，测试后发现是网速问题，所以采用本地源\r\n\r\n搭建本地源\r\nwget http://archive.cloudera.com/cdh5/redhat/6/x86_64/cdh/cloudera-cdh5.repo\r\nmv cloudera-cdh5.repo /ect/yum.repo.d/\r\nwget http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/cloudera-manager.repo\r\nmv cloudera-manager.repo /etc/yum.repos.d/\r\n\r\n考虑服务器下载各种不给力，vpn不稳定等问题，采用本地虚拟机下载\r\n\r\n同步包(与镜像名相同)\r\nreposync -r cloudera-cdh5\r\nreposync -r cloudera-manager\r\nreposync -r cloudera-impala\r\n\r\n将目录拷贝到70的wwwroot/cdh下\r\n进入目录，创建源\r\ncreaterepo .\r\n\r\n客户端更新源\r\nyum update\r\n\r\n安装cloudera-manager\r\n执行 ./cloudera-manager-installer.bin，本地源就是爽很快安装完成。\r\n使用了默认数据库，值得商榷。\r\n\r\n卸载\r\n执行/usr/share/cmf/uninstall-cloudera-manager.sh\r\nrm -rf /var/lib/cloudera-scm-server-db/data\r\n\r\n测试默认安装后，以后的安装过程会从网络下载包，为使用本地源使用如下命令\r\n./cloudera-manager-installer.bin --skip_repo_package=1\r\n不太清楚是否管用，更改*.repo文件命名，测试管用\r\n\r\ncloudera管理功能非常强大，开始尝试组件集群\r\n规划\r\n70：管理机，软件源\r\n备选机器\r\n71,72,73,74,75,76,87,88,\r\n\r\n88,87 namenode 4g 88 mysql\r\n88,87,75,76,74 datanode 2g\r\n88作为模板机\r\n\r\n所有集群重新安装系统，开始新的旅程\r\n\r\n-------------------------------------------------------2014 2 26-------------------------------------------------------------\r\n安装完成后进行检查，发现两个健康问题\r\n1. Cloudera recommends setting /proc/sys/vm/swappiness to 0. Current setting is 60. Use the sysctl command to change this setting at runtime and edit /etc/sysctl.conf for this setting to be saved after a reboot. You may continue with installation, but you may run into issues with Cloudera Manager reporting that your hosts are unhealthy because they are swapping. The following hosts are affected: \r\n\r\n/proc/sys/vm/swappiness \r\n该文件表示系统进行交换行为的程度，数值（0-100）越高，越可能发生磁盘交换，默认为60\r\n当该参数=0，表示只要有可能就尽力避免交换进程移出物理内存；\r\n当该参数=100，这告诉内核疯狂的将数据移出物理内存移到swap缓存中。\r\n配置/etc/sysctl.conf\r\n\tvm.swappiness=0\r\n立即生效\r\n\tsysctl –p\r\n\r\n已启用“透明大页面”，它可能会导致重大的性能问题。版本为“CentOS release 6.3 (Final)”且版本为“2.6.32-279.el6.x86_64”的 Kernel 已将 enabled 设置为“[always] never”，并将 defrag 设置为“[always] never”。请运行“echo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag”以禁用此设置，然后将同一命令添加到一个 init 脚本中，如 /etc/rc.local，这样当系统重启时就会设置它。或者，升级到 RHEL 6.4 或更新版本，它们不存在此错误。将会影响到以下主机\r\n透明超大页面 (THP)。THP 是一个提取层，可自动创建、管理和使用超大页面的大多数方面。\r\n\r\n修改/etc/rc.local\r\n\techo never > /sys/kernel/mm/redhat_transparent_hugepage/defrag\r\n\r\n设置同步时间\r\n\tcp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime\r\n\tyum install -y ntpdate\r\n\tntpdate us.pool.ntp.org\r\n\thwclock -w //写入bios，防止重启后时间重置。\r\n\r\n周期同步时间，每天同步时间，每周写入bios\r\ncrontab -e (分钟，小时，天，月，周)\r\n\t0       0       *       *       *       ntpdate us.pool.ntp.org\r\n\t0       0       *       *       0       hwclock -w\r\n\r\n\r\n-------------------------------------------------------2014 2 27-------------------------------------------------------------\r\n启动发现74内存占用比其他机器多，故检查74状态\r\n\ttop + M 按内存使用情况排序\r\n发现zookeeper占用内存最多，猜测zookeeper可能为管理节点，zookeeper默认选举最后一台机器为管理节点\r\n\techo stat |nc 10.106.1.74 2181 （向10.106.1.74 2181 发送stat命令）\r\n\r\n修改内存配置，namenode加大内存\r\n-HADOOP_NAMENODE_OPTS=-Xms699400192 -Xmx699400192 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:-CMSConcurrentMTEnabled -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:OnOutOfMemoryError={{AGENT_COMMON_DIR}}/killparent.sh\r\n5\t\r\n+HADOOP_NAMENODE_OPTS=-Xms1073741824 -Xmx1073741824 -XX:+UseParNewGC -XX:+UseConcMarkSweepGC -XX:-CMSConcurrentMTEnabled -XX:CMSInitiatingOccupancyFraction=70 -XX:+CMSParallelRemarkEnabled -XX:OnOutOfMemoryError={{AGENT_COMMON_DIR}}/killparent.sh\r\n6\t6\t\r\n HADOOP_ROOT_LOGGER=INFO,RFA\r\n\r\n提示新的问题，扩大second namenode设置\r\n\r\n安装了mapreduce及hbase服务\r\n重启zookeeper，发现所有依赖于zookeeper的服务都自动重启了\r\n\r\n关闭agent命令\r\n/etc/init.d/cloudera-scm-agent hard_restart\r\n\r\nservice cloudera-scm-server restart\r\n\r\n添加mysql-java包\r\n将包拷贝到/usr/share/cmf/lib\r\n\r\n一直无法使用监控，原来是没添加服务，添加服务管理后就可以进行监控了\r\n\r\n启动监控后，服务器很快进驻不健康状态，提示问题为clock offset。查看后发现问题原因是没有启动ntpd服务，修复步骤\r\n1.修改/etc/ntp.conf文件，增加以下设置\r\n\tserver us.pool.ntp.org\r\n2.启动ntp服务\r\n\tservice ntpd start\r\n3.验证\r\n\tntpdc -c loopinfo\r\n4.将ntpd服务添加到启动中\r\n\tchkconfig ntpd on\r\n\r\n\r\nHBase  Canary 用于检测HBase 系统的状态。它对指定表的每一个region 抓取一行，来探测失败或者延迟。\r\n默认情况下启动该服务，造成cpu持续高负载\r\n修改/usr/lib64/cmf/service/hbase/hbase.sh文件，注释掉hbase_canary调用后，cpu负载下降\r\n\tif [ \"regionserver\" = \"$1\" -a -n \"$CANARY_TIMEOUT\" ]; then\r\n#    \thbase_canary &\r\n     \techo 1\r\n  \tfi\r\n\r\n-------------------------------------------------------2014 3 04-------------------------------------------------------------\r\n该写导入mysql类，增强通用性\r\n\r\n开始实践新环境hbase+mapreduce任务。\r\n1.开始阶段遇到找不到hbase类的问题，修改/usr/lib/hadoop/bin/hadoop\r\n\tfor f in /usr/lib/hbase/lib/*.jar; do\r\n        CLASSPATH=${CLASSPATH}:$f;\r\n    done\r\n    明天学习任务启动机制！！\r\n2.执行hadoop jar mapreduce.CountAge 遇到权限问题，切换到hdfs用户后解决\r\n3.遇到域名解析错误，暂时没找到解决方法，但是意外发现不影响运行。\r\n4.对600w数据进行测试，统计时间大概为8分钟，预计2000w数据不超过半小时，似乎性能好了很多。继续导入数据，增大测试数据集。\r\n\r\n------------------------------------------------------2014 3 05-------------------------------------------------------------\r\n早晨一来发现两个问题，第一导入数据的程序不是最新版，还是无法正常生产日志。第二个问题，76的regionserver挂了，检查日志，发现是因为传说中的gc问题。\r\n测试大概一千万数据的年龄统计，用时9m42s。似乎效率提高了很多，详细测试有待继续\r\n下午的任务\r\n1.学习map/reduce作业提交机制\r\n2.下载zookeeper和spark的书\r\n3.写一个map/reduce程序，统计hbase一共多少行，现在统计太慢了，采用配置化或者参数形式，增加通用性。\r\n4.有机会看一下内存回收机制\r\n\r\n\r\nmap.entry\r\n\t\r\n\r\n------------------------------------------------------2014 3 06-------------------------------------------------------------\r\n上午看了会hbase表设计，有点纠结solr的设置，所以跟踪了一下\r\n前台启动脚本调用\r\n/usr/lib64/cmf/service/solr/solr.sh\r\nsolr.sh调用\r\n/usr/lib/solr/bin/solrd\r\nsolrd中对tomcat的参数进行了设置，包括hdfs的相关设置，并调用catalina.sh启动tomcat\r\n看来cloudera采用的方法为不修改默认的配置文件，而是在运行时增加参数的方法\r\n根据官方文档还可以采用修改solrconfig.xml的方式\r\n\r\n为集群建立共享文件夹，设置在88的/root/share下\r\n编写第一个coprocessor\r\n\r\n alter 'weizhang2', METHOD => 'table_att','coprocessor' => 'file:///root/share/myCoprocessor.jar|hbase.MyObserver|1001|'\r\n put 'weizhang2','123','info:value','123'\r\nalter 'weizhang2', METHOD => 'table_att','coprocessor' => 'file:///root/myCoprocessor.jar|hbase.MyObserver|USER'\r\n\r\nalter 't1', METHOD => 'table_att_unset', NAME => 'coprocessor$1'\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}